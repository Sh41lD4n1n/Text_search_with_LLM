{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147d63d6-cc6d-41ed-a329-585711d4261c",
   "metadata": {},
   "source": [
    "# Search embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ad5dd4-5517-407f-93ce-820918ae8340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61597329-7942-491f-b5c8-eee51c55ffee",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf23b1b-ca71-4e1b-888e-c836454146c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we store constant varables with path to our datasets\n",
    "# SEARCH_DATA_INDEX_PATH = \"../../datasets\" #\"../../datasets/metadata_for_search\"\n",
    "# MODEL_PATH = \"../../models/\"\n",
    "\n",
    "# SEARCH_DATA_PATH = \"../../datasets\"\n",
    "# Here we store constant varables with path to our datasets\n",
    "SEARCH_DATA_INDEX_PATH = \"../../datasets/processed_datasets\"\n",
    "MODEL_PATH = \"../../models/\"\n",
    "\n",
    "SEARCH_DATA_PATH = \"../../datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f877337e-b83f-48eb-9c91-bb62a7122fce",
   "metadata": {},
   "source": [
    "#### load search data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc98c701-030f-4171-b22c-2aa82fa4cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_vote = pd.read_json(SEARCH_DATA_PATH+\"/search_dataset_vote.json\")\n",
    "data_active = pd.read_json(SEARCH_DATA_PATH+\"/search_dataset_active.json\")\n",
    "data_hot = pd.read_json(SEARCH_DATA_PATH+\"/search_dataset_hot.json\")\n",
    "\n",
    "search_data_index_hot = pd.read_csv(SEARCH_DATA_INDEX_PATH+\"/metadata-for-search-info-hottest-rating.csv\")\n",
    "search_data_index_vote = pd.read_csv(SEARCH_DATA_INDEX_PATH+\"/metadata-for-search-info.csv\")\n",
    "search_data_index_active = pd.read_csv(SEARCH_DATA_INDEX_PATH+\"/metadata-for-search-info-active-rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa6ab98-3f51-48d8-bf48-87c213af60c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query name</th>\n",
       "      <th>rating_active</th>\n",
       "      <th>path to metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top 1000 Movies Dataset</td>\n",
       "      <td>1</td>\n",
       "      <td>ritiksharma07/imdb-top-1000-movies-dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Top 1000 Movies Dataset</td>\n",
       "      <td>2</td>\n",
       "      <td>emanchauhdary/imdb-top-1000-dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Top 1000 Movies Dataset</td>\n",
       "      <td>3</td>\n",
       "      <td>sharathmudigoudr/imdb-movie-dataset-from-year-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Top 1000 Movies Dataset</td>\n",
       "      <td>4</td>\n",
       "      <td>kunalduttads/tmdb-top-10000-10k-movies-dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Top 1000 Movies Dataset</td>\n",
       "      <td>5</td>\n",
       "      <td>dogacelik/google-data-analytics-capstone-proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>classification</td>\n",
       "      <td>16</td>\n",
       "      <td>nourmekkijj/stress-and-anxiety-posts-on-reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>classification</td>\n",
       "      <td>17</td>\n",
       "      <td>sabunbalt/skin-disease-classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>classification</td>\n",
       "      <td>18</td>\n",
       "      <td>carloscortes18/players-chess-pieces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>classification</td>\n",
       "      <td>19</td>\n",
       "      <td>haicouheba/car-classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>classification</td>\n",
       "      <td>20</td>\n",
       "      <td>micscodes/dresden-image-database</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>457 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  query name  rating_active  \\\n",
       "0    Top 1000 Movies Dataset              1   \n",
       "1    Top 1000 Movies Dataset              2   \n",
       "2    Top 1000 Movies Dataset              3   \n",
       "3    Top 1000 Movies Dataset              4   \n",
       "4    Top 1000 Movies Dataset              5   \n",
       "..                       ...            ...   \n",
       "452           classification             16   \n",
       "453           classification             17   \n",
       "454           classification             18   \n",
       "455           classification             19   \n",
       "456           classification             20   \n",
       "\n",
       "                                      path to metadata  \n",
       "0           ritiksharma07/imdb-top-1000-movies-dataset  \n",
       "1                  emanchauhdary/imdb-top-1000-dataset  \n",
       "2    sharathmudigoudr/imdb-movie-dataset-from-year-...  \n",
       "3       kunalduttads/tmdb-top-10000-10k-movies-dataset  \n",
       "4    dogacelik/google-data-analytics-capstone-proje...  \n",
       "..                                                 ...  \n",
       "452     nourmekkijj/stress-and-anxiety-posts-on-reddit  \n",
       "453              sabunbalt/skin-disease-classification  \n",
       "454                carloscortes18/players-chess-pieces  \n",
       "455                      haicouheba/car-classification  \n",
       "456                   micscodes/dresden-image-database  \n",
       "\n",
       "[457 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_data_index_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6b2cd2-d7f1-4fbf-96e2-5d42452ccbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0        0\n",
       " 1        1\n",
       " 2        2\n",
       " 3        3\n",
       " 4        4\n",
       "       ... \n",
       " 684    685\n",
       " 685    686\n",
       " 686    687\n",
       " 687    688\n",
       " 688    689\n",
       " Name: id, Length: 689, dtype: int64,\n",
       " 0       Top 10000 Popular Movies Dataset Top 10000 Po...\n",
       " 1       IMDB Top 1000 Movies Dataset \"Release Year, D...\n",
       " 2       Top 1000 IMDb Movies Dataset Discover the Gre...\n",
       " 3       Top Rated 10000 Movies Dataset (IMDB) In this...\n",
       " 4       Top 1000 Highest Grossing Movies Top 1000 Hig...\n",
       "                              ...                        \n",
       " 684     Scene Classification Contains ~25K images fro...\n",
       " 685     Plants Classification 30 Types of Plants Imag...\n",
       " 686     Flower Classification 14 Types of Flower Imag...\n",
       " 687     BIRDS 525  SPECIES- IMAGE CLASSIFICATION 525 ...\n",
       " 688     Brain Tumor Classification (MRI) Classify MRI...\n",
       " Name: text, Length: 689, dtype: object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hot['id'], data_hot['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6396c90a-545d-4069-956c-91e47fa015d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = search_data_index_vote['query name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0485093-939e-4c8e-a91e-e5eddbc22e1f",
   "metadata": {},
   "source": [
    "## Inference batching utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d3b30fd-d769-4f2a-866f-7cbba27b2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batch(dataset,batch_size=128):\n",
    "    for i in range(0,len(dataset),batch_size):\n",
    "        yield dataset[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ea71676-1978-46ff-95ab-f362bb256af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object iterate_batch at 0x7f96b466c510>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterate_batch([1,2,3,4,5,6,7,8,9,10],3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a96b153-e606-4ccf-b8d2-91ab7c0d456a",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07703895-4368-44bb-9b0a-1a829b30854e",
   "metadata": {},
   "source": [
    "### Standart models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10339e26-9410-4dcf-a86a-592907a49643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e673c26-3bc3-4b04-96ce-90fe1911e88b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### top 1 Salesforce/SFR-Embedding-2_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d98ff42-d9c1-4fc1-9e9b-5ab5e571a4ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.13s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer_SFR = AutoTokenizer.from_pretrained('Salesforce/SFR-Embedding-2_R',cache_dir=MODEL_PATH)\n",
    "model_SFR = AutoModel.from_pretrained('Salesforce/SFR-Embedding-2_R',cache_dir=MODEL_PATH)\n",
    "\n",
    "def sfr_model_inference(text=None,dataset=None):\n",
    "    global tokenizer_SFR\n",
    "    global model_SFR\n",
    "    def last_token_pool(last_hidden_states: Tensor,\n",
    "                     attention_mask: Tensor) -> Tensor:\n",
    "        left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "        if left_padding:\n",
    "            return last_hidden_states[:, -1]\n",
    "        else:\n",
    "            sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "            batch_size = last_hidden_states.shape[0]\n",
    "            return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "    \n",
    "    def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "        return f'Instruct: {task_description}\\nQuery: {query}'\n",
    "\n",
    "    # Query process\n",
    "    # Each query must come with a one-sentence instruction that describes the task\n",
    "    # task = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "    # queries = [\n",
    "    #     get_detailed_instruct(task, '<Query1>'),\n",
    "    #     get_detailed_instruct(task, '<Query2>')\n",
    "    # ]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # load model and tokenizer\n",
    "        tokenizer = tokenizer_SFR\n",
    "        model = model_SFR\n",
    "        model = model.to(device)\n",
    "        embeddings = 0\n",
    "        model.eval()\n",
    "\n",
    "        if text is None:\n",
    "            text = list(dataset[\"text_str\"])\n",
    "        for batch in iterate_batch(text,10):\n",
    "            # get the embeddings\n",
    "            embedding=0\n",
    "            try:\n",
    "                model = model.to(device)\n",
    "                max_length = 4096\n",
    "                batch_dict = tokenizer(batch, max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "                outputs = model(**batch_dict)\n",
    "                embedding = last_token_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "            \n",
    "                # normalize embeddings\n",
    "                embedding = F.normalize(embedding, p=2, dim=1)\n",
    "                embedding = embedding.to('cpu')\n",
    "    \n",
    "                if type(embeddings) is int:\n",
    "                    embeddings = embedding\n",
    "                else:\n",
    "                    embeddings = torch.cat((embeddings,embedding),dim=0)\n",
    "            except torch.cuda.OutOfMemoryError:\n",
    "                del model\n",
    "                del batch_dict\n",
    "                del embedding\n",
    "                torch.cuda.empty_cache()\n",
    "                raise torch.cuda.OutOfMemoryError\n",
    "            del embedding\n",
    "            del batch_dict\n",
    "            torch.cuda.empty_cache()\n",
    "        del model\n",
    "        del tokenizer\n",
    "        torch.cuda.empty_cache()\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587d51d-3289-4c12-b364-33c67bf1a39f",
   "metadata": {},
   "source": [
    "### Load vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a0d4f35-48f8-4e38-9216-e331ae466673",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_hot = []\n",
    "all_results_vote = []\n",
    "all_results_active = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18c09080-4f88-499f-9a4b-30041eab66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9099342c-3238-460c-a65c-79326e055d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Optional, cast\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from chromadb.api.types import EmbeddingFunction, Documents, Embeddings\n",
    "\n",
    "\n",
    "class TransformerEmbeddingFunction(EmbeddingFunction[Documents]):\n",
    "    def __init__(\n",
    "            self, model_name\n",
    "    ):\n",
    "        self.model_name=model_name\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "\n",
    "        return run_gte_model(text=input,model_path=model_name).tolist()\n",
    "\n",
    "    def preprocess_query(self,text_list):\n",
    "        return text_list\n",
    "\n",
    "class TransformerEmbeddingFunction_SFR(EmbeddingFunction[Documents]):\n",
    "    def __init__(\n",
    "            self\n",
    "    ):\n",
    "        return\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "\n",
    "        return sfr_model_inference(text=input).tolist()\n",
    "    \n",
    "    def preprocess_query(self,text_list):\n",
    "        text_list = [ f\"Instruct: Given a web search query,\\\n",
    "                      retrieve relevant passages that answer the query\\nQuery: {text}\"\n",
    "            for text in text_list]\n",
    "        return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57e71953-08a6-4254-9b5f-7ccbdc5eb028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name=\"thenlper/gte-large\"\n",
    "# model_embed = TransformerEmbeddingFunction(model_name)\n",
    "model_name=\"SFR\"\n",
    "model_embed = TransformerEmbeddingFunction_SFR()\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89e235ef-8854-4dc3-ab91-9328e54dbe48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SFR'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d2b3b1d-915d-4c1c-96d4-7e3ffd4872dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_time = 0\n",
    "search_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cf6a649-e242-4c17-a17a-e1708a6a5ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.delete_collection(\"seach_db_vote\")\n",
    "# client.delete_collection(\"seach_db_active\")\n",
    "# client.delete_collection(\"seach_db_hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf114de5-3996-40b3-bbd7-175462f5ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f044fc91-e511-4e43-a9a2-894f8cdb31d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import time\n",
    "\n",
    "metrics[model_name] = {\"active\":{},\"vote\":{},\"hot\":{}}\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "collection_vote = client.create_collection(\"seach_db_vote\",get_or_create=False,embedding_function=model_embed)\n",
    "collection_active = client.create_collection(\"seach_db_active\",get_or_create=False,embedding_function=model_embed)\n",
    "collection_hot = client.create_collection(\"seach_db_hot\",get_or_create=False,embedding_function=model_embed)\n",
    "# collection = client.create_collection(\"test_seach_fb\",embedding_function,get_or_create=True)\n",
    "\n",
    "# load\n",
    "load_time = time.time()\n",
    "collection_vote.add(\n",
    "    documents=list(data_vote['text']),\n",
    "    ids=[str(i) for i in data_vote['id']]\n",
    ")\n",
    "load_time = time.time() - load_time\n",
    "metrics[model_name]['vote']['load_time'] = load_time\n",
    "\n",
    "load_time = time.time()\n",
    "collection_active.add(\n",
    "    documents=list(data_active['text']),\n",
    "    ids=[str(i) for i in data_active['id']]\n",
    ")\n",
    "load_time = time.time() - load_time\n",
    "metrics[model_name]['active']['load_time'] = load_time\n",
    "\n",
    "load_time = time.time()\n",
    "collection_hot.add(\n",
    "    documents=list(data_hot['text']),\n",
    "    ids=[str(i) for i in data_hot['id']]\n",
    ")\n",
    "load_time = time.time() - load_time\n",
    "metrics[model_name]['hot']['load_time'] = load_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b7d8523-22d6-4148-8c90-cfc768afcd29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_time = time.time()\n",
    "queries = list(search_data_index_vote['query name'].unique())\n",
    "queries = model_embed.preprocess_query(queries)\n",
    "results_vote = collection_vote.query(\n",
    "    query_texts=queries, # Chroma will embed this for you\n",
    "    n_results=40 # how many results to return\n",
    ")\n",
    "search_time = time.time() - search_time\n",
    "metrics[model_name]['vote']['search_time'] = search_time\n",
    "\n",
    "search_time = time.time()\n",
    "queries = list(search_data_index_hot['query name'].unique())\n",
    "queries = model_embed.preprocess_query(queries)\n",
    "results_hot = collection_hot.query(\n",
    "    query_texts=queries, # Chroma will embed this for you\n",
    "    n_results=40 # how many results to return\n",
    ")\n",
    "search_time = time.time() - search_time\n",
    "metrics[model_name]['hot']['search_time'] = search_time\n",
    "\n",
    "search_time = time.time()\n",
    "queries = list(search_data_index_active['query name'].unique())\n",
    "queries = model_embed.preprocess_query(queries)\n",
    "results_active = collection_active.query(\n",
    "    query_texts=queries, # Chroma will embed this for you\n",
    "    n_results=40 # how many results to return\n",
    ")\n",
    "search_time = time.time() - search_time\n",
    "metrics[model_name]['active']['search_time'] = search_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678d7570-b2d8-40e1-88e2-76f606551451",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e76fd-133a-45e1-adae-9dec6412ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_hot.query(query_texts=[\"anime\",\"recomendation system\"],n_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f01841-622c-4fdc-9181-e3f2cc187ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_collection(\"seach_db_vote\")\n",
    "client.delete_collection(\"seach_db_active\")\n",
    "client.delete_collection(\"seach_db_hot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f77150-cabb-46f3-a3c7-051dd053fd99",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluation\n",
    "https://www.cs.cmu.edu/~ytsvetko/papers/qvec.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c91370e4-7b7a-4408-a885-3d158b523495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4234bae-d1c2-46e3-983c-c31c02fb3ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate_algs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "241a0dc6-bc12-45fd-8337-ada6dfab215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ranx import Qrels, Run\n",
    "\"\"\"\n",
    "This code provides functions for creating and evaluating\n",
    "document ranking systems using the ranx library\n",
    "\"\"\"\n",
    "\n",
    "def create_qrels(index_data,column_name):\n",
    "    \"\"\"\n",
    "    This function creates a Qrels object from the index_data DataFrame.\n",
    "    It iterates over the unique queries in the index_data DataFrame.\n",
    "    For each query, it creates a dictionary mapping document IDs to their corresponding ratings.\n",
    "    The function returns a Qrels object containing the query-document relevance scores.\n",
    "    \"\"\"\n",
    "    qrels_dict = {}\n",
    "    # index_data = search_data_index_hot\n",
    "    queries = index_data['query name'].unique()\n",
    "    \n",
    "    for i in range(len(queries)):\n",
    "        current_queries = queries[i]\n",
    "        query_dict = {}\n",
    "        current_index = index_data[index_data['query name']==current_queries]\n",
    "        for doc_idx,rating in zip(current_index.index,current_index[column_name]):\n",
    "            query_dict[str(doc_idx)] = rating\n",
    "        qrels_dict[str(i)] = query_dict\n",
    "    return Qrels(qrels_dict)\n",
    "\n",
    "def create_run(results,index_data):\n",
    "    \"\"\"\n",
    "    This function creates a Run object from the results dictionary and index_data DataFrame.\n",
    "    It iterates over the unique queries in the index_data DataFrame.\n",
    "    For each query, it creates a dictionary mapping document IDs to their corresponding scores (calculated as 1 / (distance + 1e-10)).\n",
    "    The function returns a Run object containing the query-document scores.\n",
    "    \"\"\"\n",
    "    runs = {}\n",
    "    queries = index_data['query name'].unique()\n",
    "    results\n",
    "    for i in range(len(queries)):\n",
    "        \n",
    "        res_dict = {}\n",
    "        for doc_idx,rating in zip(results['ids'][i],results['distances'][i]):\n",
    "            res_dict[str(doc_idx)] = 1/(rating+1e-10)\n",
    "        runs[str(i)] = res_dict\n",
    "    return Run(runs)\n",
    "\n",
    "\n",
    "from ranx import compare, evaluate\n",
    "\n",
    "def evaluate_algs(results,index_data,column_name):\n",
    "    \"\"\"\n",
    "    This function evaluates the performance of an information retrieval system.\n",
    "    It calls the create_qrels and create_run functions to create the Qrels and Run objects.\n",
    "    It defines a list of evaluation metrics to be used, including recall, precision, hits, MAP, MRR, and NDCG at ranks 10 and 40.\n",
    "    The function returns the evaluation results using the evaluate function from ranx.\n",
    "    \"\"\"\n",
    "    qrels = create_qrels(index_data,column_name)\n",
    "    run = create_run(results,index_data)\n",
    "    \n",
    "    metrics = [\"recall@10\",\"precision@10\",\"hits@10\",\"map@10\", \"mrr@10\", \"ndcg@10\"]\n",
    "    metrics += [\"recall@40\",\"precision@40\",\"hits@40\",\"map@40\", \"mrr@40\", \"ndcg@40\"]\n",
    "    return evaluate(qrels, run, metrics,make_comparable=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c645933-e8d9-469c-94f7-15a9774da2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_algs(results_list,index_data,column_name):\n",
    "    metrics = [\"recall@10\",\"precision@10\",\"hits@10\",\"map@10\", \"mrr@10\", \"ndcg@10\"]\n",
    "    metrics += [\"recall@40\",\"precision@40\",\"hits@40\",\"map@40\", \"mrr@40\", \"ndcg@40\"]\n",
    "    \n",
    "    qrels = create_qrels(index_data,column_name)\n",
    "    runs = [create_run(result,index_data) for result in results_list]\n",
    "    \n",
    "    return compare(\n",
    "    qrels=qrels,\n",
    "    runs=runs,\n",
    "    metrics=metrics,\n",
    "    max_p=0.01,  # P-value threshold\n",
    "    make_comparable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f69a263-cd97-4cf3-bc3a-e3a96817f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[model_name]['vote']['metrics'] = evaluate_algs(results_vote,search_data_index_vote,column_name='rating')\n",
    "metrics[model_name]['active']['metrics'] = evaluate_algs(results_active,search_data_index_active,column_name='rating_active')\n",
    "metrics[model_name]['hot']['metrics'] = evaluate_algs(results_hot,search_data_index_hot,column_name='rating_hottest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "48774f2a-7dbc-4f57-a891-b09d46a8b06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@10': 0.24509114992859457,\n",
       " 'precision@10': 0.5978260869565217,\n",
       " 'hits@10': 5.978260869565218,\n",
       " 'map@10': 0.19335366085282796,\n",
       " 'mrr@10': 0.8148550724637681,\n",
       " 'ndcg@10': 0.38780801956713495,\n",
       " 'recall@40': 0.5591251293854966,\n",
       " 'precision@40': 0.46304347826086967,\n",
       " 'hits@40': 18.52173913043478,\n",
       " 'map@40': 0.4029660422193646,\n",
       " 'mrr@40': 0.8159992372234935,\n",
       " 'ndcg@40': 0.48027479681135155}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[model_name]['vote']['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c9591c5-2135-4276-8568-7dfa1027cad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@10': 0.5775219298245614,\n",
       " 'precision@10': 0.5605263157894737,\n",
       " 'hits@10': 5.605263157894737,\n",
       " 'map@10': 0.46619869987468665,\n",
       " 'mrr@10': 0.8173976608187135,\n",
       " 'ndcg@10': 0.5564827486649929,\n",
       " 'recall@40': 0.8576597744360903,\n",
       " 'precision@40': 0.25789473684210523,\n",
       " 'hits@40': 10.31578947368421,\n",
       " 'map@40': 0.6390193875472306,\n",
       " 'mrr@40': 0.8173976608187135,\n",
       " 'ndcg@40': 0.6518684108367149}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[model_name]['active']['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fede8f32-d41e-4903-b06e-578559833bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@10': 0.4800489914126278,\n",
       " 'precision@10': 0.6568181818181817,\n",
       " 'hits@10': 6.568181818181818,\n",
       " 'map@10': 0.4212802985354392,\n",
       " 'mrr@10': 0.9128787878787878,\n",
       " 'ndcg@10': 0.4656944557747741,\n",
       " 'recall@40': 0.879333103764922,\n",
       " 'precision@40': 0.3414772727272727,\n",
       " 'hits@40': 13.659090909090908,\n",
       " 'map@40': 0.6726354645065095,\n",
       " 'mrr@40': 0.9128787878787878,\n",
       " 'ndcg@40': 0.6368186735738115}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[model_name]['hot']['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86552b8-e745-4aa8-8c47-e3d1bffc0f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
