{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147d63d6-cc6d-41ed-a329-585711d4261c",
   "metadata": {},
   "source": [
    "# Search embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61597329-7942-491f-b5c8-eee51c55ffee",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf23b1b-ca71-4e1b-888e-c836454146c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we store constant varables with path to our datasets\n",
    "# SEARCH_DATA_INDEX_PATH = \"../../datasets\" #\"../../datasets/metadata_for_search\"\n",
    "# MODEL_PATH = \"../../models/\"\n",
    "\n",
    "# SEARCH_DATA_PATH = \"../../datasets\"\n",
    "# Here we store constant varables with path to our datasets\n",
    "SEARCH_DATA_INDEX_PATH = \"../../datasets/processed_datasets\"\n",
    "MODEL_PATH = \"../../models/\"\n",
    "\n",
    "SEARCH_DATA_PATH = \"../../datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f877337e-b83f-48eb-9c91-bb62a7122fce",
   "metadata": {},
   "source": [
    "#### load search data from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc98c701-030f-4171-b22c-2aa82fa4cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# here we load metadata (related to source of dataset)\n",
    "data_vote = pd.read_json(SEARCH_DATA_PATH+\"/search_dataset_vote.json\")\n",
    "data_active = pd.read_json(SEARCH_DATA_PATH+\"/search_dataset_active.json\")\n",
    "data_hot = pd.read_json(SEARCH_DATA_PATH+\"/search_dataset_hot.json\")\n",
    "\n",
    "# here we load datasets (texts)\n",
    "search_data_index_hot = pd.read_csv(SEARCH_DATA_INDEX_PATH+\"/metadata-for-search-info-hottest-rating.csv\")\n",
    "search_data_index_vote = pd.read_csv(SEARCH_DATA_INDEX_PATH+\"/metadata-for-search-info.csv\")\n",
    "search_data_index_active = pd.read_csv(SEARCH_DATA_INDEX_PATH+\"/metadata-for-search-info-active-rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427e9640-0a4f-46c3-94a1-3c2cde41db9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "      <th>titleNullable</th>\n",
       "      <th>subtitleNullable</th>\n",
       "      <th>descriptionNullable</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/raw_datasets/metadata-for-search/o...</td>\n",
       "      <td>0</td>\n",
       "      <td>Top 10000 Popular Movies Dataset</td>\n",
       "      <td>Top 10000 Popular movies based on TMDB ratings</td>\n",
       "      <td>### Context\\n\\nRecommendation systems are used...</td>\n",
       "      <td>[arts and entertainment, movies and tv shows, ...</td>\n",
       "      <td>Top 10000 Popular Movies Dataset</td>\n",
       "      <td>Top 10000 Popular movies based on TMDB ratings</td>\n",
       "      <td>### Context\\n\\nRecommendation systems are used...</td>\n",
       "      <td>Top 10000 Popular Movies Dataset Top 10000 Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/raw_datasets/metadata-for-search/r...</td>\n",
       "      <td>1</td>\n",
       "      <td>IMDB Top 1000 Movies Dataset</td>\n",
       "      <td>\"Release Year, Duration, Ratings, Metascores, ...</td>\n",
       "      <td>This dataset provides comprehensive informatio...</td>\n",
       "      <td>[movies and tv shows]</td>\n",
       "      <td>IMDB Top 1000 Movies Dataset</td>\n",
       "      <td>\"Release Year, Duration, Ratings, Metascores, ...</td>\n",
       "      <td>This dataset provides comprehensive informatio...</td>\n",
       "      <td>IMDB Top 1000 Movies Dataset \"Release Year, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/raw_datasets/metadata-for-search/i...</td>\n",
       "      <td>2</td>\n",
       "      <td>Top 1000 IMDb Movies Dataset</td>\n",
       "      <td>Discover the Greatest Movies of All Time - IMD...</td>\n",
       "      <td>Welcome to the \"Top 1000 IMDb Movies Dataset\" ...</td>\n",
       "      <td>[movies and tv shows]</td>\n",
       "      <td>Top 1000 IMDb Movies Dataset</td>\n",
       "      <td>Discover the Greatest Movies of All Time - IMD...</td>\n",
       "      <td>Welcome to the \"Top 1000 IMDb Movies Dataset\" ...</td>\n",
       "      <td>Top 1000 IMDb Movies Dataset Discover the Gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../datasets/raw_datasets/metadata-for-search/u...</td>\n",
       "      <td>3</td>\n",
       "      <td>Top Rated 10000 Movies Dataset (IMDB)</td>\n",
       "      <td>In this dataset the top movies data is given b...</td>\n",
       "      <td>\\nIn this dataset all time top  movies data is...</td>\n",
       "      <td>[movies and tv shows]</td>\n",
       "      <td>Top Rated 10000 Movies Dataset (IMDB)</td>\n",
       "      <td>In this dataset the top movies data is given b...</td>\n",
       "      <td>\\nIn this dataset all time top  movies data is...</td>\n",
       "      <td>Top Rated 10000 Movies Dataset (IMDB) In this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../datasets/raw_datasets/metadata-for-search/s...</td>\n",
       "      <td>4</td>\n",
       "      <td>Top 1000 Highest Grossing Movies</td>\n",
       "      <td>Top 1000 Highest Grossing Holywood Movies</td>\n",
       "      <td>Context\\nThis dataset contains information abo...</td>\n",
       "      <td>[movies and tv shows, beginner, intermediate, ...</td>\n",
       "      <td>Top 1000 Highest Grossing Movies</td>\n",
       "      <td>Top 1000 Highest Grossing Holywood Movies</td>\n",
       "      <td>Context\\nThis dataset contains information abo...</td>\n",
       "      <td>Top 1000 Highest Grossing Movies Top 1000 Hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>../datasets/raw_datasets/metadata-for-search/n...</td>\n",
       "      <td>685</td>\n",
       "      <td>Scene Classification</td>\n",
       "      <td>Contains ~25K images from a wide range of natu...</td>\n",
       "      <td>This dataset contains about ~25k images from a...</td>\n",
       "      <td>[movies and tv shows, computer vision, classif...</td>\n",
       "      <td>Scene Classification</td>\n",
       "      <td>Contains ~25K images from a wide range of natu...</td>\n",
       "      <td>This dataset contains about ~25k images from a...</td>\n",
       "      <td>Scene Classification Contains ~25K images fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>../datasets/raw_datasets/metadata-for-search/m...</td>\n",
       "      <td>686</td>\n",
       "      <td>Plants Classification</td>\n",
       "      <td>30 Types of Plants Image Classification</td>\n",
       "      <td>The dataset contains 30 types of plants images...</td>\n",
       "      <td>[biology, classification, image]</td>\n",
       "      <td>Plants Classification</td>\n",
       "      <td>30 Types of Plants Image Classification</td>\n",
       "      <td>The dataset contains 30 types of plants images...</td>\n",
       "      <td>Plants Classification 30 Types of Plants Imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>../datasets/raw_datasets/metadata-for-search/m...</td>\n",
       "      <td>687</td>\n",
       "      <td>Flower Classification</td>\n",
       "      <td>14 Types of Flower Image Classification</td>\n",
       "      <td>The dataset contains 14 types of flower images...</td>\n",
       "      <td>[classification, image, chinese]</td>\n",
       "      <td>Flower Classification</td>\n",
       "      <td>14 Types of Flower Image Classification</td>\n",
       "      <td>The dataset contains 14 types of flower images...</td>\n",
       "      <td>Flower Classification 14 Types of Flower Imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>../datasets/raw_datasets/metadata-for-search/g...</td>\n",
       "      <td>688</td>\n",
       "      <td>BIRDS 525  SPECIES- IMAGE CLASSIFICATION</td>\n",
       "      <td>525 species, 84635 train, 2625 test, 2625 vali...</td>\n",
       "      <td>This version of the dataset adds 10 new specie...</td>\n",
       "      <td>[biology, computer vision, classification, cnn...</td>\n",
       "      <td>BIRDS 525  SPECIES- IMAGE CLASSIFICATION</td>\n",
       "      <td>525 species, 84635 train, 2625 test, 2625 vali...</td>\n",
       "      <td>This version of the dataset adds 10 new specie...</td>\n",
       "      <td>BIRDS 525  SPECIES- IMAGE CLASSIFICATION 525 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>../datasets/raw_datasets/metadata-for-search/s...</td>\n",
       "      <td>689</td>\n",
       "      <td>Brain Tumor Classification (MRI)</td>\n",
       "      <td>Classify MRI images into four classes</td>\n",
       "      <td># Contribute to OpenSource\\n##Repo: [GitHub](h...</td>\n",
       "      <td>[health, medicine, classification, health cond...</td>\n",
       "      <td>Brain Tumor Classification (MRI)</td>\n",
       "      <td>Classify MRI images into four classes</td>\n",
       "      <td># Contribute to OpenSource\\n##Repo: [GitHub](h...</td>\n",
       "      <td>Brain Tumor Classification (MRI) Classify MRI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path   id  \\\n",
       "0    ../datasets/raw_datasets/metadata-for-search/o...    0   \n",
       "1    ../datasets/raw_datasets/metadata-for-search/r...    1   \n",
       "2    ../datasets/raw_datasets/metadata-for-search/i...    2   \n",
       "3    ../datasets/raw_datasets/metadata-for-search/u...    3   \n",
       "4    ../datasets/raw_datasets/metadata-for-search/s...    4   \n",
       "..                                                 ...  ...   \n",
       "684  ../datasets/raw_datasets/metadata-for-search/n...  685   \n",
       "685  ../datasets/raw_datasets/metadata-for-search/m...  686   \n",
       "686  ../datasets/raw_datasets/metadata-for-search/m...  687   \n",
       "687  ../datasets/raw_datasets/metadata-for-search/g...  688   \n",
       "688  ../datasets/raw_datasets/metadata-for-search/s...  689   \n",
       "\n",
       "                                        title  \\\n",
       "0            Top 10000 Popular Movies Dataset   \n",
       "1                IMDB Top 1000 Movies Dataset   \n",
       "2                Top 1000 IMDb Movies Dataset   \n",
       "3       Top Rated 10000 Movies Dataset (IMDB)   \n",
       "4            Top 1000 Highest Grossing Movies   \n",
       "..                                        ...   \n",
       "684                      Scene Classification   \n",
       "685                     Plants Classification   \n",
       "686                     Flower Classification   \n",
       "687  BIRDS 525  SPECIES- IMAGE CLASSIFICATION   \n",
       "688          Brain Tumor Classification (MRI)   \n",
       "\n",
       "                                              subtitle  \\\n",
       "0       Top 10000 Popular movies based on TMDB ratings   \n",
       "1    \"Release Year, Duration, Ratings, Metascores, ...   \n",
       "2    Discover the Greatest Movies of All Time - IMD...   \n",
       "3    In this dataset the top movies data is given b...   \n",
       "4            Top 1000 Highest Grossing Holywood Movies   \n",
       "..                                                 ...   \n",
       "684  Contains ~25K images from a wide range of natu...   \n",
       "685            30 Types of Plants Image Classification   \n",
       "686            14 Types of Flower Image Classification   \n",
       "687  525 species, 84635 train, 2625 test, 2625 vali...   \n",
       "688              Classify MRI images into four classes   \n",
       "\n",
       "                                           description  \\\n",
       "0    ### Context\\n\\nRecommendation systems are used...   \n",
       "1    This dataset provides comprehensive informatio...   \n",
       "2    Welcome to the \"Top 1000 IMDb Movies Dataset\" ...   \n",
       "3    \\nIn this dataset all time top  movies data is...   \n",
       "4    Context\\nThis dataset contains information abo...   \n",
       "..                                                 ...   \n",
       "684  This dataset contains about ~25k images from a...   \n",
       "685  The dataset contains 30 types of plants images...   \n",
       "686  The dataset contains 14 types of flower images...   \n",
       "687  This version of the dataset adds 10 new specie...   \n",
       "688  # Contribute to OpenSource\\n##Repo: [GitHub](h...   \n",
       "\n",
       "                                              keywords  \\\n",
       "0    [arts and entertainment, movies and tv shows, ...   \n",
       "1                                [movies and tv shows]   \n",
       "2                                [movies and tv shows]   \n",
       "3                                [movies and tv shows]   \n",
       "4    [movies and tv shows, beginner, intermediate, ...   \n",
       "..                                                 ...   \n",
       "684  [movies and tv shows, computer vision, classif...   \n",
       "685                   [biology, classification, image]   \n",
       "686                   [classification, image, chinese]   \n",
       "687  [biology, computer vision, classification, cnn...   \n",
       "688  [health, medicine, classification, health cond...   \n",
       "\n",
       "                                titleNullable  \\\n",
       "0            Top 10000 Popular Movies Dataset   \n",
       "1                IMDB Top 1000 Movies Dataset   \n",
       "2                Top 1000 IMDb Movies Dataset   \n",
       "3       Top Rated 10000 Movies Dataset (IMDB)   \n",
       "4            Top 1000 Highest Grossing Movies   \n",
       "..                                        ...   \n",
       "684                      Scene Classification   \n",
       "685                     Plants Classification   \n",
       "686                     Flower Classification   \n",
       "687  BIRDS 525  SPECIES- IMAGE CLASSIFICATION   \n",
       "688          Brain Tumor Classification (MRI)   \n",
       "\n",
       "                                      subtitleNullable  \\\n",
       "0       Top 10000 Popular movies based on TMDB ratings   \n",
       "1    \"Release Year, Duration, Ratings, Metascores, ...   \n",
       "2    Discover the Greatest Movies of All Time - IMD...   \n",
       "3    In this dataset the top movies data is given b...   \n",
       "4            Top 1000 Highest Grossing Holywood Movies   \n",
       "..                                                 ...   \n",
       "684  Contains ~25K images from a wide range of natu...   \n",
       "685            30 Types of Plants Image Classification   \n",
       "686            14 Types of Flower Image Classification   \n",
       "687  525 species, 84635 train, 2625 test, 2625 vali...   \n",
       "688              Classify MRI images into four classes   \n",
       "\n",
       "                                   descriptionNullable  \\\n",
       "0    ### Context\\n\\nRecommendation systems are used...   \n",
       "1    This dataset provides comprehensive informatio...   \n",
       "2    Welcome to the \"Top 1000 IMDb Movies Dataset\" ...   \n",
       "3    \\nIn this dataset all time top  movies data is...   \n",
       "4    Context\\nThis dataset contains information abo...   \n",
       "..                                                 ...   \n",
       "684  This dataset contains about ~25k images from a...   \n",
       "685  The dataset contains 30 types of plants images...   \n",
       "686  The dataset contains 14 types of flower images...   \n",
       "687  This version of the dataset adds 10 new specie...   \n",
       "688  # Contribute to OpenSource\\n##Repo: [GitHub](h...   \n",
       "\n",
       "                                                  text  \n",
       "0     Top 10000 Popular Movies Dataset Top 10000 Po...  \n",
       "1     IMDB Top 1000 Movies Dataset \"Release Year, D...  \n",
       "2     Top 1000 IMDb Movies Dataset Discover the Gre...  \n",
       "3     Top Rated 10000 Movies Dataset (IMDB) In this...  \n",
       "4     Top 1000 Highest Grossing Movies Top 1000 Hig...  \n",
       "..                                                 ...  \n",
       "684   Scene Classification Contains ~25K images fro...  \n",
       "685   Plants Classification 30 Types of Plants Imag...  \n",
       "686   Flower Classification 14 Types of Flower Imag...  \n",
       "687   BIRDS 525  SPECIES- IMAGE CLASSIFICATION 525 ...  \n",
       "688   Brain Tumor Classification (MRI) Classify MRI...  \n",
       "\n",
       "[689 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6b2cd2-d7f1-4fbf-96e2-5d42452ccbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0        0\n",
       " 1        1\n",
       " 2        2\n",
       " 3        3\n",
       " 4        4\n",
       "       ... \n",
       " 684    685\n",
       " 685    686\n",
       " 686    687\n",
       " 687    688\n",
       " 688    689\n",
       " Name: id, Length: 689, dtype: int64,\n",
       " 0       Top 10000 Popular Movies Dataset Top 10000 Po...\n",
       " 1       IMDB Top 1000 Movies Dataset \"Release Year, D...\n",
       " 2       Top 1000 IMDb Movies Dataset Discover the Gre...\n",
       " 3       Top Rated 10000 Movies Dataset (IMDB) In this...\n",
       " 4       Top 1000 Highest Grossing Movies Top 1000 Hig...\n",
       "                              ...                        \n",
       " 684     Scene Classification Contains ~25K images fro...\n",
       " 685     Plants Classification 30 Types of Plants Imag...\n",
       " 686     Flower Classification 14 Types of Flower Imag...\n",
       " 687     BIRDS 525  SPECIES- IMAGE CLASSIFICATION 525 ...\n",
       " 688     Brain Tumor Classification (MRI) Classify MRI...\n",
       " Name: text, Length: 689, dtype: object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hot['id'], data_hot['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6396c90a-545d-4069-956c-91e47fa015d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = search_data_index_vote['query name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecafd6e-8a62-41a6-919b-4ea7063b7dbf",
   "metadata": {},
   "source": [
    "#### load dataset Ubuntu questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad37f619-4fc2-4ced-a30a-1a03f13515e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ask_dataset = load_dataset(\"mteb/askubuntudupquestions-reranking\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b29611b4-8bb6-4ebc-a938-221083144483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['query', 'positive', 'negative'],\n",
       "        num_rows: 375\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df2d55ee-8023-4d61-a3fe-98f4399c8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(sample):\n",
    "    sample['responce'] = sample['positive']+sample['negative']\n",
    "    sample['target'] = list(range(len(sample['responce'])))\n",
    "    return sample\n",
    "ask_dataset1 = ask_dataset.map(process_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a96b153-e606-4ccf-b8d2-91ab7c0d456a",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0485093-939e-4c8e-a91e-e5eddbc22e1f",
   "metadata": {},
   "source": [
    "### Inference batching utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d3b30fd-d769-4f2a-866f-7cbba27b2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function return batches of our datasets\n",
    "def iterate_batch(dataset,batch_size=128):\n",
    "    for i in range(0,len(dataset),batch_size):\n",
    "        yield dataset[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ea71676-1978-46ff-95ab-f362bb256af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object iterate_batch at 0x7f52ac12a570>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterate_batch([1,2,3,4,5,6,7,8,9,10],3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e673c26-3bc3-4b04-96ce-90fe1911e88b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### qween"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aa08e1a-335a-4184-a666-6cab7f2812d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Optional, cast\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from chromadb.api.types import EmbeddingFunction, Documents, Embeddings\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "class TransformerEmbeddingFunction_Qween(EmbeddingFunction[Documents]):    \n",
    "    \"\"\"\n",
    "    The TransformerEmbeddingFunction_Qween class is an embedding function\n",
    "    that uses a pre-trained transformer model to generate embeddings for a\n",
    "    given set of documents. It is designed to work with the ChromaDB\n",
    "    library for building vector search engines.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Load a pre-trained tokenizer and model from the 'Alibaba-NLP/gte-Qwen2-7B-instruct' model\n",
    "        checkpoint\n",
    "        It also sets the max_length parameter, which is the maximum length of input sequences\n",
    "        that the model can handle.\n",
    "        \"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('Alibaba-NLP/gte-Qwen2-7B-instruct', trust_remote_code=True)\n",
    "        self.model = AutoModel.from_pretrained('Alibaba-NLP/gte-Qwen2-7B-instruct', trust_remote_code=True)\n",
    "        self.model = self.model.to(device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.max_length = 8192\n",
    "        return\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        \"\"\"\n",
    "        The __call__ method is the main entry point for generating embeddings. It takes a list of documents as input and returns a list of embeddings.\n",
    "        It first defines a helper function called last_token_pool that extracts the embedding of the last token from the model's output. This is done by checking if the input sequence has left padding and selecting the appropriate token index.\n",
    "        The input documents are tokenized using the tokenizer and passed through the model to obtain the last hidden states.\n",
    "        The last_token_pool function is applied to the last hidden states to extract the final embeddings.\n",
    "        The embeddings are converted to a list and returned.\n",
    "        \"\"\"\n",
    "        \n",
    "        def last_token_pool(last_hidden_states: Tensor,attention_mask: Tensor) -> Tensor:\n",
    "            left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "            if left_padding:\n",
    "                return last_hidden_states[:, -1]\n",
    "            else:\n",
    "                sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "                batch_size = last_hidden_states.shape[0]\n",
    "                return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "        embeddings = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in iterate_batch(input,3):\n",
    "                embedding=0\n",
    "            \n",
    "                batch_dict = self.tokenizer(batch, max_length=self.max_length, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "                outputs = self.model(**batch_dict)\n",
    "                embedding = last_token_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "                \n",
    "                if type(embeddings) is int:\n",
    "                        embeddings = embedding\n",
    "                else:\n",
    "                    embeddings = torch.cat((embeddings,embedding),dim=0)\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        return embeddings.tolist()\n",
    "    \n",
    "    def preprocess_query(self,text_list):\n",
    "        \"\"\"\n",
    "        The preprocess_query method is used to preprocess the input queries before generating embeddings.\n",
    "        It defines a task description and a helper function called get_detailed_instruct that appends the task description to each query.\n",
    "        The method applies the get_detailed_instruct function to each query in the input list and returns the preprocessed queries.\n",
    "        Overall, this code provides a convenient way to use a pre-trained transformer model for generating document embeddings in the context of a vector search engine built with ChromaDB.        \n",
    "        \"\"\"\n",
    "        \n",
    "        task = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "        def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "            return f'Instruct: {task_description}\\nQuery: {query}'\n",
    "\n",
    "        text_list = [get_detailed_instruct(task, text) for text in text_list]\n",
    "        return text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587d51d-3289-4c12-b364-33c67bf1a39f",
   "metadata": {},
   "source": [
    "### Load vector database for kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74672989-37e9-462b-b545-2b474b023a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6ae56f94c44c23b5da31c210bd93a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model_embed = TransformerEmbeddingFunction_Qween()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a0d4f35-48f8-4e38-9216-e331ae466673",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_hot = []\n",
    "all_results_vote = []\n",
    "all_results_active = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18c09080-4f88-499f-9a4b-30041eab66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89e235ef-8854-4dc3-ab91-9328e54dbe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"qween\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d2b3b1d-915d-4c1c-96d4-7e3ffd4872dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_time = 0\n",
    "search_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cf6a649-e242-4c17-a17a-e1708a6a5ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.delete_collection(\"seach_db_vote\")\n",
    "# client.delete_collection(\"seach_db_active\")\n",
    "# client.delete_collection(\"seach_db_hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf114de5-3996-40b3-bbd7-175462f5ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f044fc91-e511-4e43-a9a2-894f8cdb31d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import time\n",
    "\n",
    "metrics[model_name] = {\"active\":{},\"vote\":{},\"hot\":{}}\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "collection_vote = client.create_collection(\"seach_db_vote\",get_or_create=False,embedding_function=model_embed)\n",
    "collection_active = client.create_collection(\"seach_db_active\",get_or_create=False,embedding_function=model_embed)\n",
    "collection_hot = client.create_collection(\"seach_db_hot\",get_or_create=False,embedding_function=model_embed)\n",
    "# collection = client.create_collection(\"test_seach_fb\",embedding_function,get_or_create=True)\n",
    "\n",
    "# load\n",
    "load_time = time.time()\n",
    "collection_vote.add(\n",
    "    documents=list(data_vote['text']),\n",
    "    ids=[str(i) for i in data_vote['id']]\n",
    ")\n",
    "load_time = time.time() - load_time\n",
    "metrics[model_name]['vote']['load_time'] = load_time\n",
    "\n",
    "load_time = time.time()\n",
    "collection_active.add(\n",
    "    documents=list(data_active['text']),\n",
    "    ids=[str(i) for i in data_active['id']]\n",
    ")\n",
    "load_time = time.time() - load_time\n",
    "metrics[model_name]['active']['load_time'] = load_time\n",
    "\n",
    "load_time = time.time()\n",
    "collection_hot.add(\n",
    "    documents=list(data_hot['text']),\n",
    "    ids=[str(i) for i in data_hot['id']]\n",
    ")\n",
    "load_time = time.time() - load_time\n",
    "metrics[model_name]['hot']['load_time'] = load_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b7d8523-22d6-4148-8c90-cfc768afcd29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_time = time.time()\n",
    "queries = list(search_data_index_vote['query name'].unique())\n",
    "queries = model_embed.preprocess_query(queries)\n",
    "results_vote = collection_vote.query(\n",
    "    query_texts=queries, # Chroma will embed this for you\n",
    "    n_results=40 # how many results to return\n",
    ")\n",
    "search_time = time.time() - search_time\n",
    "metrics[model_name]['vote']['search_time'] = search_time\n",
    "\n",
    "search_time = time.time()\n",
    "queries = list(search_data_index_hot['query name'].unique())\n",
    "queries = model_embed.preprocess_query(queries)\n",
    "results_hot = collection_hot.query(\n",
    "    query_texts=queries, # Chroma will embed this for you\n",
    "    n_results=40 # how many results to return\n",
    ")\n",
    "search_time = time.time() - search_time\n",
    "metrics[model_name]['hot']['search_time'] = search_time\n",
    "\n",
    "search_time = time.time()\n",
    "queries = list(search_data_index_active['query name'].unique())\n",
    "queries = model_embed.preprocess_query(queries)\n",
    "results_active = collection_active.query(\n",
    "    query_texts=queries, # Chroma will embed this for you\n",
    "    n_results=40 # how many results to return\n",
    ")\n",
    "search_time = time.time() - search_time\n",
    "metrics[model_name]['active']['search_time'] = search_time\n",
    "\n",
    "client.delete_collection(\"seach_db_vote\")\n",
    "client.delete_collection(\"seach_db_active\")\n",
    "client.delete_collection(\"seach_db_hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "943594fe-03bd-4faf-87d3-49950daeea5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['query', 'positive', 'negative', 'responce', 'target'],\n",
       "        num_rows: 375\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_dataset1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c13580-9c62-45dd-a441-5a0f1539a941",
   "metadata": {},
   "source": [
    "### load vector base for ask ubuntu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775eeaaf-298d-4641-9652-d3fc2dcb7adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62e7f152-4290-4c14-878e-b11e2e62928c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmetrics2\u001b[49m[model_name] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mubuntu\u001b[39m\u001b[38;5;124m\"\u001b[39m:{}}\n\u001b[1;32m      6\u001b[0m client \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mClient()\n\u001b[1;32m      8\u001b[0m collection_ubuntu \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mcreate_collection(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseach_db_ubuntu\u001b[39m\u001b[38;5;124m\"\u001b[39m,get_or_create\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,embedding_function\u001b[38;5;241m=\u001b[39mmodel_embed)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics2' is not defined"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import time\n",
    "\n",
    "metrics2[model_name] = {\"ubuntu\":{}}\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "collection_ubuntu = client.create_collection(\"seach_db_ubuntu\",get_or_create=False,embedding_function=model_embed)\n",
    "# collection = client.create_collection(\"test_seach_fb\",embedding_function,get_or_create=True)\n",
    "\n",
    "# load\n",
    "load_time = time.time()\n",
    "collection_vote.add(\n",
    "    documents=list(ask_dataset1['responce'])\n",
    ")\n",
    "load_time = time.time() - load_time\n",
    "metrics[model_name]['vote']['load_time'] = load_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fea093-75eb-4d46-8625-64ec57b83a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_time = time.time()\n",
    "queries = list(search_data_index_vote['query name'].unique())\n",
    "queries = model_embed.preprocess_query(queries)\n",
    "results_vote = collection_vote.query(\n",
    "    query_texts=queries, # Chroma will embed this for you\n",
    "    n_results=40 # how many results to return\n",
    ")\n",
    "search_time = time.time() - search_time\n",
    "metrics[model_name]['vote']['search_time'] = search_time\n",
    "\n",
    "client.delete_collection(\"seach_db_hot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f77150-cabb-46f3-a3c7-051dd053fd99",
   "metadata": {},
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00c2405c-5209-4fb0-9dc8-8ae212f55408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12771d54-dcdb-4f7c-9c45-6f0d2f8bd608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ea1f37-3342-4fab-aa24-f21dd61b4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate_algs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b335fe02-1596-4c01-9626-6501b5d55704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danil/Text_search_with_LLM/sample/lib/python3.10/site-packages/ranx/metrics/recall.py:29: NumbaTypeSafetyWarning: unsafe cast from uint64 to int64. Precision may be lost.\n",
      "  scores[i] = _recall(qrels[i], run[i], k, rel_lvl)\n"
     ]
    }
   ],
   "source": [
    "metrics[model_name]['vote']['metrics'] = evaluate_algs(results_vote,search_data_index_vote,column_name='rating')\n",
    "metrics[model_name]['active']['metrics'] = evaluate_algs(results_active,search_data_index_active,column_name='rating_active')\n",
    "metrics[model_name]['hot']['metrics'] = evaluate_algs(results_hot,search_data_index_hot,column_name='rating_hottest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7273f380-f929-4a8b-b745-5b682a87e4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@10': 0.2288268800739379,\n",
       " 'precision@10': 0.5782608695652174,\n",
       " 'hits@10': 5.782608695652174,\n",
       " 'map@10': 0.18642717258326347,\n",
       " 'mrr@10': 0.7815217391304349,\n",
       " 'ndcg@10': 0.390860835402863,\n",
       " 'recall@40': 0.5568091062932357,\n",
       " 'precision@40': 0.46141304347826095,\n",
       " 'hits@40': 18.456521739130434,\n",
       " 'map@40': 0.40018413730541147,\n",
       " 'mrr@40': 0.7826659038901601,\n",
       " 'ndcg@40': 0.48348643757160337}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[model_name]['vote']['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d6e91d8-8226-45b5-958c-f93e7fdc1e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@10': 0.537359022556391,\n",
       " 'precision@10': 0.531578947368421,\n",
       " 'hits@10': 5.315789473684211,\n",
       " 'map@10': 0.42852861319966573,\n",
       " 'mrr@10': 0.7907894736842105,\n",
       " 'ndcg@10': 0.5269621411880194,\n",
       " 'recall@40': 0.8498746867167922,\n",
       " 'precision@40': 0.2513157894736842,\n",
       " 'hits@40': 10.052631578947368,\n",
       " 'map@40': 0.6052456815282098,\n",
       " 'mrr@40': 0.7953748006379586,\n",
       " 'ndcg@40': 0.6456429264912914}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[model_name]['active']['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b201ca17-587d-4b8b-9d30-99d50e90407b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@10': 0.4683898803216984,\n",
       " 'precision@10': 0.6249999999999999,\n",
       " 'hits@10': 6.25,\n",
       " 'map@10': 0.3976503272160739,\n",
       " 'mrr@10': 0.8358585858585859,\n",
       " 'ndcg@10': 0.44386353572764725,\n",
       " 'recall@40': 0.8556416437098256,\n",
       " 'precision@40': 0.32784090909090907,\n",
       " 'hits@40': 13.113636363636363,\n",
       " 'map@40': 0.6334733570628028,\n",
       " 'mrr@40': 0.8369408369408369,\n",
       " 'ndcg@40': 0.6110369817475614}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[model_name]['hot']['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710caa53-7dee-4bd9-947a-251726bab1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sample",
   "language": "python",
   "name": "sample"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
