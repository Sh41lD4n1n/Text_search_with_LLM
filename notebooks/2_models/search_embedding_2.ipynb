{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147d63d6-cc6d-41ed-a329-585711d4261c",
   "metadata": {},
   "source": [
    "# Search embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b798e4-37aa-463c-a666-d9567b5c8cbf",
   "metadata": {},
   "source": [
    "Virtual environment\n",
    "https://www.geeksforgeeks.org/using-jupyter-notebook-in-virtual-environment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ad5dd4-5517-407f-93ce-820918ae8340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61597329-7942-491f-b5c8-eee51c55ffee",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bf23b1b-ca71-4e1b-888e-c836454146c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we store constant varables with path to our datasets\n",
    "DATA_INDEX_PATH = \"../../datasets/\"\n",
    "MODEL_PATH = \"../../models/\"\n",
    "\n",
    "SEARCH_DATA_PATH = \"../../datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f877337e-b83f-48eb-9c91-bb62a7122fce",
   "metadata": {},
   "source": [
    "#### load search data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc98c701-030f-4171-b22c-2aa82fa4cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# here we load metadata (related to source of dataset)\n",
    "data_vote = pd.read_json(SEARCH_DATA_PATH+\"/search_dataset_vote.json\")\n",
    "data_active = pd.read_json(SEARCH_DATA_PATH+\"/search_dataset_active.json\")\n",
    "data_hot = pd.read_json(SEARCH_DATA_PATH+\"/search_dataset_hot.json\")\n",
    "\n",
    "# here we load datasets (texts)\n",
    "search_data_index_hot = pd.read_csv(SEARCH_DATA_INDEX_PATH+\"/metadata-for-search-info-hottest-rating.csv\")\n",
    "search_data_index_vote = pd.read_csv(SEARCH_DATA_INDEX_PATH+\"/metadata-for-search-info.csv\")\n",
    "search_data_index_active = pd.read_csv(SEARCH_DATA_INDEX_PATH+\"/metadata-for-search-info-active-rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f6b2cd2-d7f1-4fbf-96e2-5d42452ccbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0        0\n",
       " 1        1\n",
       " 2        2\n",
       " 3        3\n",
       " 4        4\n",
       "       ... \n",
       " 684    685\n",
       " 685    686\n",
       " 686    687\n",
       " 687    688\n",
       " 688    689\n",
       " Name: id, Length: 689, dtype: int64,\n",
       " 0       Top 10000 Popular Movies Dataset Top 10000 Po...\n",
       " 1       IMDB Top 1000 Movies Dataset \"Release Year, D...\n",
       " 2       Top 1000 IMDb Movies Dataset Discover the Gre...\n",
       " 3       Top Rated 10000 Movies Dataset (IMDB) In this...\n",
       " 4       Top 1000 Highest Grossing Movies Top 1000 Hig...\n",
       "                              ...                        \n",
       " 684     Scene Classification Contains ~25K images fro...\n",
       " 685     Plants Classification 30 Types of Plants Imag...\n",
       " 686     Flower Classification 14 Types of Flower Imag...\n",
       " 687     BIRDS 525  SPECIES- IMAGE CLASSIFICATION 525 ...\n",
       " 688     Brain Tumor Classification (MRI) Classify MRI...\n",
       " Name: text, Length: 689, dtype: object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hot['id'], data_hot['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6396c90a-545d-4069-956c-91e47fa015d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = search_data_index_vote['query name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a96b153-e606-4ccf-b8d2-91ab7c0d456a",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0485093-939e-4c8e-a91e-e5eddbc22e1f",
   "metadata": {},
   "source": [
    "### Inference batching utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d3b30fd-d769-4f2a-866f-7cbba27b2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function return batches \n",
    "def iterate_batch(dataset,batch_size=128):\n",
    "    for i in range(0,len(dataset),batch_size):\n",
    "        yield dataset[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ea71676-1978-46ff-95ab-f362bb256af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object iterate_batch at 0x7f62712f5f50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterate_batch([1,2,3,4,5,6,7,8,9,10],3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e673c26-3bc3-4b04-96ce-90fe1911e88b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### qween"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6aa08e1a-335a-4184-a666-6cab7f2812d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Optional, cast\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from chromadb.api.types import EmbeddingFunction, Documents, Embeddings\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "class TransformerEmbeddingFunction_Qween(EmbeddingFunction[Documents]):\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('Alibaba-NLP/gte-Qwen2-7B-instruct', trust_remote_code=True)\n",
    "        self.model = AutoModel.from_pretrained('Alibaba-NLP/gte-Qwen2-7B-instruct', trust_remote_code=True)\n",
    "        \n",
    "        self.max_length = 8192\n",
    "        return\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        \n",
    "        def last_token_pool(last_hidden_states: Tensor,attention_mask: Tensor) -> Tensor:\n",
    "            left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "            if left_padding:\n",
    "                return last_hidden_states[:, -1]\n",
    "            else:\n",
    "                sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "                batch_size = last_hidden_states.shape[0]\n",
    "                return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "        batch_dict = self.tokenizer(input, max_length=self.max_length, padding=True, truncation=True, return_tensors='pt')\n",
    "        outputs = self.model(**batch_dict)\n",
    "        embeddings = last_token_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        return embeddings.tolist()\n",
    "    \n",
    "    def preprocess_query(self,text_list):\n",
    "        task = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "        def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "            return f'Instruct: {task_description}\\nQuery: {query}'\n",
    "\n",
    "        text_list = [get_detailed_instruct(task, text) for text in text_list]\n",
    "        return text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587d51d-3289-4c12-b364-33c67bf1a39f",
   "metadata": {},
   "source": [
    "### Load vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74672989-37e9-462b-b545-2b474b023a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ffe02cddad4a1d8f93e9b6c5ec3fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_embed = TransformerEmbeddingFunction_Qween()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d4f35-48f8-4e38-9216-e331ae466673",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_hot = []\n",
    "all_results_vote = []\n",
    "all_results_active = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c09080-4f88-499f-9a4b-30041eab66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e235ef-8854-4dc3-ab91-9328e54dbe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"qween\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2b3b1d-915d-4c1c-96d4-7e3ffd4872dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_time = 0\n",
    "search_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6a649-e242-4c17-a17a-e1708a6a5ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.delete_collection(\"seach_db_vote\")\n",
    "# client.delete_collection(\"seach_db_active\")\n",
    "# client.delete_collection(\"seach_db_hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf114de5-3996-40b3-bbd7-175462f5ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f044fc91-e511-4e43-a9a2-894f8cdb31d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import time\n",
    "\n",
    "metrics[model_name] = {\"active\":{},\"vote\":{},\"hot\":{}}\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "collection_vote = client.create_collection(\"seach_db_vote\",get_or_create=False,embedding_function=model_embed)\n",
    "collection_active = client.create_collection(\"seach_db_active\",get_or_create=False,embedding_function=model_embed)\n",
    "collection_hot = client.create_collection(\"seach_db_hot\",get_or_create=False,embedding_function=model_embed)\n",
    "# collection = client.create_collection(\"test_seach_fb\",embedding_function,get_or_create=True)\n",
    "\n",
    "# load\n",
    "load_time = time.time()\n",
    "collection_vote.add(\n",
    "    documents=list(data_vote['text']),\n",
    "    ids=[str(i) for i in data_vote['id']]\n",
    ")\n",
    "load_time = time.time() - load_time\n",
    "metrics[model_name]['vote']['load_time'] = load_time\n",
    "\n",
    "load_time = time.time()\n",
    "collection_active.add(\n",
    "    documents=list(data_active['text']),\n",
    "    ids=[str(i) for i in data_active['id']]\n",
    ")\n",
    "load_time = time.time() - load_time\n",
    "metrics[model_name]['active']['load_time'] = load_time\n",
    "\n",
    "load_time = time.time()\n",
    "collection_hot.add(\n",
    "    documents=list(data_hot['text']),\n",
    "    ids=[str(i) for i in data_hot['id']]\n",
    ")\n",
    "load_time = time.time() - load_time\n",
    "metrics[model_name]['hot']['load_time'] = load_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7d8523-22d6-4148-8c90-cfc768afcd29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_time = time.time()\n",
    "queries = list(search_data_index_vote['query name'].unique())\n",
    "queries = model_embed.preprocess_query(queries)\n",
    "results_vote = collection_vote.query(\n",
    "    query_texts=queries, # Chroma will embed this for you\n",
    "    n_results=40 # how many results to return\n",
    ")\n",
    "search_time = time.time() - search_time\n",
    "metrics[model_name]['vote']['search_time'] = search_time\n",
    "\n",
    "search_time = time.time()\n",
    "queries = list(search_data_index_hot['query name'].unique())\n",
    "queries = model_embed.preprocess_query(queries)\n",
    "results_hot = collection_hot.query(\n",
    "    query_texts=queries, # Chroma will embed this for you\n",
    "    n_results=40 # how many results to return\n",
    ")\n",
    "search_time = time.time() - search_time\n",
    "metrics[model_name]['hot']['search_time'] = search_time\n",
    "\n",
    "search_time = time.time()\n",
    "queries = list(search_data_index_active['query name'].unique())\n",
    "queries = model_embed.preprocess_query(queries)\n",
    "results_active = collection_active.query(\n",
    "    query_texts=queries, # Chroma will embed this for you\n",
    "    n_results=40 # how many results to return\n",
    ")\n",
    "search_time = time.time() - search_time\n",
    "metrics[model_name]['active']['search_time'] = search_time\n",
    "\n",
    "client.delete_collection(\"seach_db_vote\")\n",
    "client.delete_collection(\"seach_db_active\")\n",
    "client.delete_collection(\"seach_db_hot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f77150-cabb-46f3-a3c7-051dd053fd99",
   "metadata": {},
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c2405c-5209-4fb0-9dc8-8ae212f55408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ea1f37-3342-4fab-aa24-f21dd61b4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate_algs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335fe02-1596-4c01-9626-6501b5d55704",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[model_name]['vote']['metrics'] = evaluate_algs(results_vote,search_data_index_vote)\n",
    "metrics[model_name]['active']['metrics'] = evaluate_algs(results_active,search_data_index_active)\n",
    "metrics[model_name]['hot']['metrics'] = evaluate_algs(results_hot,search_data_index_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710caa53-7dee-4bd9-947a-251726bab1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sample",
   "language": "python",
   "name": "sample"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
